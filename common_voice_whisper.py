# -*- coding: utf-8 -*-
"""COMMON_VOICE_WHISPER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OyC7daCJy_tohW48uH8UgKTwNHC0LZBD
"""

!pip install tqdm transformers librosa jiwer

from google.colab import drive

# Mount Google Drive without user interaction
drive.mount('/content/drive', force_remount=True)

import os
from transformers import pipeline
import pandas as pd
from jiwer import wer
import librosa
import logging
from tqdm import tqdm
logging.basicConfig(level=logging.INFO)

import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline

device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

model_id = "openai/whisper-large"

model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, torch_dtype=torch_dtype, use_safetensors=True
)
model.to(device)

processor = AutoProcessor.from_pretrained(model_id)

def transcriber(language,model_path,output_dir,audio_dir,lang_code,test_dataset_path,country):
    # SETTING PARAMETERS ACCORDING TO THE COUNTRY
    lower_language=language.lower()
    # if (country=='Indian'):
    #   merging_parameter='audio_filename'
    #   extension='.wav'
    #   first_index='audio_filename'
    #   wer_p='text'
    #   csv_parameter=f'{lower_language}_train.csv'
    #   test_data_loader=os.path.join(audio_dir,f'{lower_language}_train.csv')
    # else:
    merging_parameter='path'
    extension='.mp3'
    first_index='path'
    wer_p='sentence'
    csv_parameter=f'{lower_language}_metadata.csv'
    test_data_loader=test_dataset_path


    # MODEL SETTING

    pipe = pipeline(
      "automatic-speech-recognition",
      model=model,
      tokenizer=processor.tokenizer,
      feature_extractor=processor.feature_extractor,
      max_new_tokens=128,
      chunk_length_s=30,
      batch_size=16,
      return_timestamps=True,
      torch_dtype=torch_dtype,
      device=device,
      generate_kwargs={"language": language}
    )
    # TRANSCRIPTION OF THE AUDIO
    def transcribe_audio(filename):
        try:
            if filename.endswith(extension):
                logging.info(f"Processing: {filename}")
                # Load the audio file using librosa
                audio_file = os.path.join(audio_dir, filename)
                audio, sr = librosa.load(audio_file, sr=16000)  # Load and resample to 16000 Hz
                result = pipe(audio)
                transcription=result["text"]
                # Return the transcription
                logging.info(f"Transcription: {transcription}")
                filename=filename.split("/")[-1]

                return {first_index: filename, "transcription": transcription}
        except Exception as e:
            logging.error(f"Error processing file {filename}: {e}")
            return None



    def save_to_excel(transcriptions, filename="transcriptions.xlsx"):
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        filename = os.path.join(output_dir, filename)
        logging.info("Saving to Excel...")
        df = pd.DataFrame(transcriptions)
        logging.info(f"Dataframe shape: {df.shape}")
        if not os.path.exists(filename):
            df.to_excel(filename, index=False)
        else:
            with pd.ExcelWriter(filename, mode='a', if_sheet_exists='overlay') as writer:
                df.to_excel(writer, index=False, header=False, startrow=writer.sheets['Sheet1'].max_row)
        logging.info(f"Saved {len(transcriptions)} transcriptions to {filename}")

    # AUDIO FILES IN ONE LIST

    test_data_csv=pd.read_csv(test_dataset_path)
    # if country=='Indian':
    #   audio_files=[]
    #   for file in audio_dir:
    #     if file.endswith(extension):
    #       audio_path=os.path.join(audio_dir,file)
    #       if (os.path.exists(audio_path) and audio_path.endswith(".wav")):
    #         audio_files.append(audio_path)

    # else:
    audio_files=[i for i in os.listdir(audio_dir)]

    # Initialize a list to store transcriptions
    transcriptions = []
    transcription_count = 0
    skipper=0
    # Process each audio file sequentially
    for idx, filename in enumerate(tqdm(audio_files, desc="Transcribing audio files")):
        result = transcribe_audio(filename)
        if result:
            transcriptions.append(result)
            transcription_count += 1
            # Save to Excel for every 2 transcriptions
            if transcription_count % 100 == 0:
                save_to_excel(transcriptions, "transcriptions.xlsx")
                transcriptions = []  # Clear the list after saving
                #break
        logging.info(f"Transcribed {transcription_count} files so far.")

    # Save any remaining transcriptions
    if transcriptions:
        save_to_excel(transcriptions, "transcriptions.xlsx")
        logging.info(f"Final save: Total {transcription_count} transcriptions to Excel.")

    filename = os.path.join(output_dir, 'transcriptions.xlsx')
    csv_path=os.path.join(audio_dir,csv_parameter)
    language_train_excel = pd.read_csv(test_data_loader)
    transcriptions = pd.read_excel(filename)

    merged_data = pd.merge(language_train_excel, transcriptions, on=merging_parameter)

    # Write the final merged data to a new Excel file
    def calculate_wer(row):
        return wer(row[wer_p], row['transcription'])

    # Apply the WER function to each row in the merged DataFrame
    merged_data['WER'] = merged_data.apply(calculate_wer, axis=1)

    output_path=os.path.join(output_dir,f"evaluation_{sample_number}.xlsx")
    merged_data.to_excel(output_path, index=False)

    print(merged_data.head())

# Indian languages
Indian= [
    "Hindi",
    "Tamil",
    "Telugu",
    "Marathi",
    "Malayalam",
    "Gujarati",
    "Bengali",
    "Kannada",
    "Urdu",
    "Odia"
]

# African languages
African= [
    "Swahili",
    "Hausa",
    "Yoruba",
    "Igbo",
    "Amharic",
    "Oromo",
    "Swazi",
    "Zulu",
    "Kabyle"
]

supported_languages = [
    'english', 'chinese', 'german', 'spanish', 'russian', 'korean', 'french', 'japanese',
    'portuguese', 'turkish', 'polish', 'catalan', 'dutch', 'arabic', 'swedish', 'italian',
    'indonesian', 'hindi', 'finnish', 'vietnamese', 'hebrew', 'ukrainian', 'greek', 'malay',
    'czech', 'romanian', 'danish', 'hungarian', 'tamil', 'norwegian', 'thai', 'urdu', 'croatian',
    'bulgarian', 'lithuanian', 'latin', 'maori', 'malayalam', 'welsh', 'slovak', 'telugu',
    'persian', 'latvian', 'bengali', 'serbian', 'azerbaijani', 'slovenian', 'kannada',
    'estonian', 'macedonian', 'breton', 'basque', 'icelandic', 'armenian', 'nepali', 'mongolian',
    'bosnian', 'kazakh', 'albanian', 'swahili', 'galician', 'marathi', 'punjabi', 'sinhala',
    'khmer', 'shona', 'yoruba', 'somali', 'afrikaans', 'occitan', 'georgian', 'belarusian',
    'tajik', 'sindhi', 'gujarati', 'amharic', 'yiddish', 'lao', 'uzbek', 'faroese',
    'haitian creole', 'pashto', 'turkmen', 'nynorsk', 'maltese', 'sanskrit', 'luxembourgish',
    'myanmar', 'tibetan', 'tagalog', 'malagasy', 'assamese', 'tatar', 'hawaiian', 'lingala',
    'hausa', 'bashkir', 'javanese', 'sundanese', 'cantonese', 'burmese', 'valencian', 'flemish',
    'haitian', 'letzeburgesch', 'pushto', 'panjabi', 'moldavian', 'moldovan', 'sinhalese',
    'castilian', 'mandarin'
]

import os
import time
import logging

# lang_codes = {
#     'Hindi': 'hi',
#     'Bengali': 'bn',
#     'Tamil': 'ta',
#     'Telugu': 'te',
#     'Gujarati': 'gu',
#     'Kannada': 'kn',
#     'Malayalam': 'ml',
#     'Marathi': 'mr',
#     'Swahili': 'sw',
#     'Hausa': 'ha',
#     'Yoruba': 'yo',
#     'Igbo': 'ig',
#     'Amharic': 'am',
#     'Oromo': 'om',
#     'Swazi': 'ss',
#     'Zulu': 'zu',
#     'Kabyle': 'kab'
# }
lang_codes = {
    'Urdu:'
}




print(lang_codes)


sample_number = 0
low = 0
high = 1000
country=""

for language, lang_code in lang_codes.items():
    lower_language = language.lower()
    if lower_language not in supported_languages:
      print(f'{language} not in SP')
      continue;
    start_time = time.time()  # Record start time
    current_directory = os.getcwd()
    lower_language = language.lower()
    if language in Indian:
      country="Indian"

      test_dataset_path = f"/content/drive/MyDrive/Common_Voice_Multi/{lower_language}_metadata.csv"
      if not os.path.exists(test_dataset_path):
          print("test not ounf")
          logging.warning(f"Test dataset not found: {test_dataset_path}. Skipping {language}.")
          continue
      model_path = f"/content/drive/MyDrive/WHISPER_MODELS/{lower_language}_models/whisper-medium-{lang_code}_alldata_multigpu"
      output_dir = f"/content/drive/MyDrive/INTERN_RESULTS/WHISPER_LARGE/COMMON_VOICE_RESULTS/{language}"
      input_dir = f"/content/drive/MyDrive/Common_Voice_Multi/{language}"

      if not os.path.exists(input_dir):
          print("NOT FOUND")
          logging.warning(f"Input directory not found: {input_dir}. Skipping {language}.")
          continue
    # else:
    #   country="Indian"
    #   start_time = time.time()  # Record start time
    #   current_directory = os.getcwd()
    #   lower_language = language.lower()
    #   test_dataset_path = f"/content/drive/MyDrive/FLEURS_Multi/{lower_language}_metadata.csv"
    #   model_path = "" #f"/content/drive/MyDrive/WHISPER_MODELS/{lower_language}_models/whisper-medium-{lang_code}_alldata_multigpu"
    #   output_dir = f"/content/drive/MyDrive/INTERN_RESULTS/WHISPER_LARGE/FLEURS_RESULTS/{language}"
    #   input_dir = f"/content/drive/MyDrive/FLEURS_Multi/{language}"

    #   if not os.path.exists(input_dir):
    #       logging.warning(f"Input directory not found: {input_dir}. Skipping {language}.")
    #       continue

    transcriber(language, model_path, output_dir, input_dir, lang_code, test_dataset_path,country)